{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2011dbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/lihaoyu/miniconda3/envs/gan-env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 步骤 1: 导入所有必要的库\n",
    "# -----------------------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR\n",
    "import torch.utils.checkpoint as checkpoint \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d5541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 步骤 2: 全局超参数设置\n",
    "# -----------------------------------------------------------------------------\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_TOTAL_EPOCHS = 200\n",
    "BASE_LR = 5e-4             # AdamW 推荐的基准学习率\n",
    "NUM_WARMUP_EPOCHS = 5\n",
    "GRAD_CLIP_MAX_NORM = 5.0   # 梯度裁剪最大范数\n",
    "\n",
    "# MixUp/CutMix 参数\n",
    "mixup_alpha = 1.0\n",
    "cutmix_alpha = 1.0\n",
    "cutmix_prob = 0.5          # 0.5 的概率使用 CutMix，否则使用 MixUp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7606f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 步骤 3: 解决 NameError 的关键操作：将辅助函数置于最前方\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
    "    return windows\n",
    "\n",
    "def window_reverse(windows, window_size, H, W):\n",
    "    B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
    "    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
    "    return x\n",
    "\n",
    "# MixUp + CutMix 辅助函数\n",
    "def rand_bbox(size, lam):\n",
    "    H, W = size[2], size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cy = np.random.randint(H)\n",
    "    cx = np.random.randint(W)\n",
    "    y1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    y2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    x1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    x2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def apply_mixup(inputs, targets, alpha=mixup_alpha):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = inputs.size()[0]\n",
    "    index = torch.randperm(batch_size).to(inputs.device)\n",
    "    mixed_inputs = lam * inputs + (1 - lam) * inputs[index, :]\n",
    "    targets_a, targets_b = targets, targets[index]\n",
    "    return mixed_inputs, targets_a, targets_b, lam\n",
    "\n",
    "def apply_cutmix(inputs, targets, alpha=cutmix_alpha):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = inputs.size()[0]\n",
    "    index = torch.randperm(batch_size).to(inputs.device)\n",
    "    x1, y1, x2, y2 = rand_bbox(inputs.size(), lam)\n",
    "    inputs_new = inputs.clone()\n",
    "    inputs_new[:, :, y1:y2, x1:x2] = inputs[index, :, y1:y2, x1:x2]\n",
    "    lam = 1 - ((x2 - x1) * (y2 - y1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    "    targets_a, targets_b = targets, targets[index]\n",
    "    return inputs_new, targets_a, targets_b, lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "236de9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 步骤 4: Swin Transformer 模型结构定义 (核心组件)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "class WindowAttention(nn.Module):\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads)) \n",
    "        coords_h = torch.arange(self.window_size[0])\n",
    "        coords_w = torch.arange(self.window_size[1])\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing='ij'))\n",
    "        coords_flatten = torch.flatten(coords, 1)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1).permute(2, 0, 1).contiguous()\n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class SwinTransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        if min(self.input_resolution) <= self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.input_resolution)\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_hidden_dim),\n",
    "            act_layer(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(mlp_hidden_dim, dim),\n",
    "            nn.Dropout(drop)\n",
    "        )\n",
    "        \n",
    "        # 创新点：并行卷积分支 (Parallel Convolution Branch)\n",
    "        # 旨在融合局部归纳偏置 (Local Inductive Bias) 与全局建模能力\n",
    "        self.conv_branch = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=1, groups=dim), # Depthwise Conv\n",
    "            nn.BatchNorm2d(dim),\n",
    "            act_layer()\n",
    "        )\n",
    "        self.conv_scale = nn.Parameter(torch.ones(1) * 0.1) # 可学习的融合系数\n",
    "\n",
    "    def create_mask(self, H, W):\n",
    "        if self.shift_size > 0:\n",
    "            img_mask = torch.zeros((1, H, W, 1))\n",
    "            h_slices = (slice(0, -self.window_size), slice(-self.window_size, -self.shift_size), slice(-self.shift_size, None))\n",
    "            w_slices = (slice(0, -self.window_size), slice(-self.window_size, -self.shift_size), slice(-self.shift_size, None))\n",
    "            cnt = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    img_mask[:, h, w, :] = cnt\n",
    "                    cnt += 1\n",
    "            # 这里的 window_partition 现在已经定义在全局范围\n",
    "            mask_windows = window_partition(img_mask, self.window_size)\n",
    "            mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n",
    "            attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "            attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "        else:\n",
    "            attn_mask = None\n",
    "        return attn_mask\n",
    "    def forward(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = x.view(B, H, W, C)\n",
    "        \n",
    "        # 并行卷积分支前向传播\n",
    "        x_conv = x.permute(0, 3, 1, 2) # B, C, H, W\n",
    "        x_conv = self.conv_branch(x_conv).permute(0, 2, 3, 1).view(B, L, C) # B, L, C\n",
    "        \n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "            attn_mask = self.create_mask(H, W).to(x.device)\n",
    "        else:\n",
    "            shifted_x = x\n",
    "            attn_mask = None\n",
    "        # 这里的 window_partition 不再报错\n",
    "        x_windows = window_partition(shifted_x, self.window_size).view(-1, self.window_size * self.window_size, C)\n",
    "        attn_windows = self.attn(x_windows, mask=attn_mask)\n",
    "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
    "        # 这里的 window_reverse 不再报错\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, H, W)\n",
    "        if self.shift_size > 0:\n",
    "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = x.view(B, H * W, C)\n",
    "        \n",
    "        # 融合机制：Transformer 特征 + 卷积特征\n",
    "        x = shortcut + self.drop_path(x) + self.drop_path(x_conv * self.conv_scale)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "class PatchMerging(nn.Module):\n",
    "    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.input_resolution = input_resolution\n",
    "        self.dim = dim\n",
    "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False) \n",
    "        self.norm = norm_layer(4 * dim)\n",
    "    def forward(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        x = x.view(B, H, W, C)\n",
    "        x0 = x[:, 0::2, 0::2, :]\n",
    "        x1 = x[:, 1::2, 0::2, :]\n",
    "        x2 = x[:, 0::2, 1::2, :]\n",
    "        x3 = x[:, 1::2, 1::2, :]\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)\n",
    "        x = x.view(B, -1, 4 * C)\n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)\n",
    "        return x\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=4, in_chans=3, embed_dim=96, norm_layer=None):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.patches_resolution = patches_resolution\n",
    "        self.num_patches = patches_resolution[0] * patches_resolution[1]\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer is not None else None\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "class BasicLayer(nn.Module):\n",
    "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
    "                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        if isinstance(drop_path, list):\n",
    "             dpr = drop_path\n",
    "        else:\n",
    "             dpr = [drop_path] * depth \n",
    "        self.blocks = nn.ModuleList([\n",
    "            SwinTransformerBlock(dim=dim, input_resolution=input_resolution, num_heads=num_heads, window_size=window_size,\n",
    "                                 shift_size=0 if (i % 2 == 0) else window_size // 2, mlp_ratio=mlp_ratio,\n",
    "                                 qkv_bias=qkv_bias, drop=drop, attn_drop=attn_drop,\n",
    "                                 drop_path=dpr[i], norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "        self.downsample = downsample(input_resolution, dim=dim, norm_layer=nn.LayerNorm) if downsample is not None else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x = blk(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "class SwinTransformer(nn.Module):\n",
    "    def __init__(self, img_size=32, patch_size=2, in_chans=3, num_classes=10,\n",
    "                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
    "                 window_size=4, mlp_ratio=4., qkv_bias=True, drop_rate=0.1, attn_drop_rate=0.0,\n",
    "                 drop_path_rate=0.2, norm_layer=nn.LayerNorm, ape=False, patch_norm=True,\n",
    "                 use_checkpoint=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_features = int(embed_dim * 2**(self.num_layers - 1))\n",
    "        \n",
    "        self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n",
    "                                      norm_layer=norm_layer if patch_norm else None)\n",
    "        patches_resolution = self.patch_embed.patches_resolution\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        \n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers):\n",
    "            start_index = sum(depths[:i_layer])\n",
    "            end_index = sum(depths[:i_layer + 1])\n",
    "            layer = BasicLayer(dim=int(embed_dim * 2**i_layer),\n",
    "                               input_resolution=(patches_resolution[0] // (2**i_layer), patches_resolution[1] // (2**i_layer)),\n",
    "                               depth=depths[i_layer], num_heads=num_heads[i_layer], window_size=window_size, \n",
    "                               mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                               drop_path=dpr[start_index:end_index], \n",
    "                               norm_layer=norm_layer,\n",
    "                               downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,\n",
    "                               use_checkpoint=use_checkpoint)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.norm = norm_layer(self.num_features)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x = self.pos_drop(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.avgpool(x.transpose(1, 2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5249df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 步骤 5: SOTA 数据增强和数据加载 (CIFAR-10)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "NORM_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "NORM_STD = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.CIFAR10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(NORM_MEAN, NORM_STD),\n",
    "    transforms.RandomErasing(p=0.25),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(NORM_MEAN, NORM_STD),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c525923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 步骤 6: Warmup 调度器\n",
    "# -----------------------------------------------------------------------------\n",
    "class LinearWarmup(LambdaLR):\n",
    "    def __init__(self, optimizer, warmup_epochs, last_epoch=-1):\n",
    "        def lr_lambda(epoch):\n",
    "            if epoch < warmup_epochs:\n",
    "                return (epoch + 1) / warmup_epochs\n",
    "            return 1\n",
    "        super().__init__(optimizer, lr_lambda, last_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106e1ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 步骤 7: 改进的 Train & Test 函数 (集成 MixUp/CutMix 和 Gradient Clipping)\n",
    "# -----------------------------------------------------------------------------\n",
    "def train(epoch, net, trainloader, optimizer, criterion): \n",
    "    net.train()\n",
    "    total, correct, total_loss = 0, 0, 0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for inputs, targets in trainloader:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        # MixUp/CutMix Logic\n",
    "        r = np.random.rand()\n",
    "        if r < cutmix_prob:\n",
    "            inputs, targets_a, targets_b, lam = apply_cutmix(inputs, targets)\n",
    "        else:\n",
    "            inputs, targets_a, targets_b, lam = apply_mixup(inputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # 混合损失计算\n",
    "        loss = lam * criterion(outputs, targets_a) + \\\n",
    "             (1 - lam) * criterion(outputs, targets_b)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度裁剪\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), max_norm=GRAD_CLIP_MAX_NORM) \n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, pred = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "\n",
    "        # MixUp/CutMix 混合准确率计算\n",
    "        correct += (lam * pred.eq(targets_a).sum().item() + \n",
    "                    (1 - lam) * pred.eq(targets_b).sum().item())\n",
    "\n",
    "    print(f\"Train Epoch {epoch+1:3d} | Loss: {total_loss/len(trainloader):.4f} \"\n",
    "          f\"| Acc (approx): {100.*correct/total:.2f}% | Time: {time.time()-t0:.1f}s\")\n",
    "\n",
    "\n",
    "def test(epoch, net, testloader, criterion):\n",
    "    net.eval()\n",
    "    correct, total = 0, 0\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in testloader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, pred = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += pred.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    print(f\"Test | Loss: {total_loss/len(testloader):.4f} \"\n",
    "          f\"| Acc: {acc:.2f}% ({correct}/{total})\")\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88584de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 实例化 Swin Transformer (Swin-T) ---\n",
      "SwinTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 96, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.018)\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.036)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.055)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.073)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.091)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.109)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.127)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.145)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.164)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.182)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.200)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (head): Linear(in_features=768, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "--- 开始 200 轮 Swin Transformer 训练 ---\n",
      "Train Epoch   1 | Loss: 2.2533 | Acc (approx): 17.03% | Time: 58.7s\n",
      "Test | Loss: 1.9713 | Acc: 29.93% (2993/10000)\n",
      "   [LR] Current LR = 0.000200\n",
      ">>>> Saved new best model (29.93%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch   2 | Loss: 2.1810 | Acc (approx): 20.78% | Time: 65.7s\n",
      "Test | Loss: 1.8187 | Acc: 38.02% (3802/10000)\n",
      "   [LR] Current LR = 0.000300\n",
      ">>>> Saved new best model (38.02%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch   3 | Loss: 2.1292 | Acc (approx): 24.12% | Time: 66.0s\n",
      "Test | Loss: 1.6993 | Acc: 45.60% (4560/10000)\n",
      "   [LR] Current LR = 0.000400\n",
      ">>>> Saved new best model (45.60%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch   4 | Loss: 2.0993 | Acc (approx): 25.89% | Time: 66.3s\n",
      "Test | Loss: 1.7490 | Acc: 41.67% (4167/10000)\n",
      "   [LR] Current LR = 0.000500\n",
      "------------------------------------------------------------\n",
      "Train Epoch   5 | Loss: 2.0563 | Acc (approx): 28.59% | Time: 56.4s\n",
      "Test | Loss: 1.5860 | Acc: 50.54% (5054/10000)\n",
      "   [LR] Current LR = 0.000500\n",
      ">>>> Saved new best model (50.54%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch   6 | Loss: 2.0230 | Acc (approx): 30.74% | Time: 44.5s\n",
      "Test | Loss: 1.5569 | Acc: 53.78% (5378/10000)\n",
      "   [LR] Current LR = 0.000500\n",
      ">>>> Saved new best model (53.78%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch   7 | Loss: 1.9906 | Acc (approx): 32.70% | Time: 44.8s\n",
      "Test | Loss: 1.5145 | Acc: 53.94% (5394/10000)\n",
      "   [LR] Current LR = 0.000500\n",
      ">>>> Saved new best model (53.94%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch   8 | Loss: 1.9695 | Acc (approx): 33.82% | Time: 44.2s\n",
      "Test | Loss: 1.5173 | Acc: 54.51% (5451/10000)\n",
      "   [LR] Current LR = 0.000500\n",
      ">>>> Saved new best model (54.51%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch   9 | Loss: 1.9633 | Acc (approx): 34.01% | Time: 44.2s\n",
      "Test | Loss: 1.4543 | Acc: 58.49% (5849/10000)\n",
      "   [LR] Current LR = 0.000499\n",
      ">>>> Saved new best model (58.49%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  10 | Loss: 1.9573 | Acc (approx): 34.57% | Time: 44.1s\n",
      "Test | Loss: 1.4343 | Acc: 57.53% (5753/10000)\n",
      "   [LR] Current LR = 0.000499\n",
      "------------------------------------------------------------\n",
      "Train Epoch  11 | Loss: 1.9298 | Acc (approx): 36.16% | Time: 43.9s\n",
      "Test | Loss: 1.4247 | Acc: 58.36% (5836/10000)\n",
      "   [LR] Current LR = 0.000499\n",
      "------------------------------------------------------------\n",
      "Train Epoch  12 | Loss: 1.9319 | Acc (approx): 35.88% | Time: 44.4s\n",
      "Test | Loss: 1.4237 | Acc: 58.65% (5865/10000)\n",
      "   [LR] Current LR = 0.000498\n",
      ">>>> Saved new best model (58.65%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  13 | Loss: 1.9149 | Acc (approx): 37.06% | Time: 43.8s\n",
      "Test | Loss: 1.3941 | Acc: 61.61% (6161/10000)\n",
      "   [LR] Current LR = 0.000498\n",
      ">>>> Saved new best model (61.61%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  14 | Loss: 1.9077 | Acc (approx): 37.20% | Time: 44.3s\n",
      "Test | Loss: 1.3790 | Acc: 61.18% (6118/10000)\n",
      "   [LR] Current LR = 0.000497\n",
      "------------------------------------------------------------\n",
      "Train Epoch  15 | Loss: 1.9086 | Acc (approx): 37.40% | Time: 44.3s\n",
      "Test | Loss: 1.3385 | Acc: 63.75% (6375/10000)\n",
      "   [LR] Current LR = 0.000497\n",
      ">>>> Saved new best model (63.75%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  16 | Loss: 1.8789 | Acc (approx): 38.92% | Time: 44.0s\n",
      "Test | Loss: 1.3302 | Acc: 63.04% (6304/10000)\n",
      "   [LR] Current LR = 0.000496\n",
      "------------------------------------------------------------\n",
      "Train Epoch  17 | Loss: 1.8825 | Acc (approx): 38.84% | Time: 44.4s\n",
      "Test | Loss: 1.3353 | Acc: 62.96% (6296/10000)\n",
      "   [LR] Current LR = 0.000495\n",
      "------------------------------------------------------------\n",
      "Train Epoch  18 | Loss: 1.8737 | Acc (approx): 39.41% | Time: 43.9s\n",
      "Test | Loss: 1.3037 | Acc: 64.07% (6407/10000)\n",
      "   [LR] Current LR = 0.000495\n",
      ">>>> Saved new best model (64.07%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  19 | Loss: 1.8706 | Acc (approx): 39.52% | Time: 44.3s\n",
      "Test | Loss: 1.3415 | Acc: 62.49% (6249/10000)\n",
      "   [LR] Current LR = 0.000494\n",
      "------------------------------------------------------------\n",
      "Train Epoch  20 | Loss: 1.8508 | Acc (approx): 40.64% | Time: 43.7s\n",
      "Test | Loss: 1.2907 | Acc: 65.11% (6511/10000)\n",
      "   [LR] Current LR = 0.000493\n",
      ">>>> Saved new best model (65.11%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  21 | Loss: 1.8625 | Acc (approx): 40.02% | Time: 44.0s\n",
      "Test | Loss: 1.3308 | Acc: 63.87% (6387/10000)\n",
      "   [LR] Current LR = 0.000492\n",
      "------------------------------------------------------------\n",
      "Train Epoch  22 | Loss: 1.8387 | Acc (approx): 41.32% | Time: 44.4s\n",
      "Test | Loss: 1.2450 | Acc: 68.05% (6805/10000)\n",
      "   [LR] Current LR = 0.000491\n",
      ">>>> Saved new best model (68.05%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  23 | Loss: 1.8437 | Acc (approx): 41.15% | Time: 44.0s\n",
      "Test | Loss: 1.2139 | Acc: 68.92% (6892/10000)\n",
      "   [LR] Current LR = 0.000490\n",
      ">>>> Saved new best model (68.92%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  24 | Loss: 1.8167 | Acc (approx): 42.65% | Time: 44.4s\n",
      "Test | Loss: 1.2394 | Acc: 68.94% (6894/10000)\n",
      "   [LR] Current LR = 0.000488\n",
      ">>>> Saved new best model (68.94%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  25 | Loss: 1.8289 | Acc (approx): 41.82% | Time: 43.8s\n",
      "Test | Loss: 1.2607 | Acc: 68.93% (6893/10000)\n",
      "   [LR] Current LR = 0.000487\n",
      "------------------------------------------------------------\n",
      "Train Epoch  26 | Loss: 1.8227 | Acc (approx): 42.43% | Time: 44.2s\n",
      "Test | Loss: 1.2425 | Acc: 67.81% (6781/10000)\n",
      "   [LR] Current LR = 0.000486\n",
      "------------------------------------------------------------\n",
      "Train Epoch  27 | Loss: 1.8222 | Acc (approx): 42.56% | Time: 44.2s\n",
      "Test | Loss: 1.2118 | Acc: 68.58% (6858/10000)\n",
      "   [LR] Current LR = 0.000484\n",
      "------------------------------------------------------------\n",
      "Train Epoch  28 | Loss: 1.8042 | Acc (approx): 43.39% | Time: 43.9s\n",
      "Test | Loss: 1.1900 | Acc: 70.16% (7016/10000)\n",
      "   [LR] Current LR = 0.000483\n",
      ">>>> Saved new best model (70.16%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  29 | Loss: 1.8113 | Acc (approx): 42.84% | Time: 44.1s\n",
      "Test | Loss: 1.2073 | Acc: 69.66% (6966/10000)\n",
      "   [LR] Current LR = 0.000482\n",
      "------------------------------------------------------------\n",
      "Train Epoch  30 | Loss: 1.7816 | Acc (approx): 44.32% | Time: 44.0s\n",
      "Test | Loss: 1.1718 | Acc: 70.96% (7096/10000)\n",
      "   [LR] Current LR = 0.000480\n",
      ">>>> Saved new best model (70.96%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  31 | Loss: 1.8004 | Acc (approx): 43.38% | Time: 44.0s\n",
      "Test | Loss: 1.1546 | Acc: 71.55% (7155/10000)\n",
      "   [LR] Current LR = 0.000478\n",
      ">>>> Saved new best model (71.55%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  32 | Loss: 1.7752 | Acc (approx): 44.99% | Time: 43.8s\n",
      "Test | Loss: 1.2192 | Acc: 69.49% (6949/10000)\n",
      "   [LR] Current LR = 0.000477\n",
      "------------------------------------------------------------\n",
      "Train Epoch  33 | Loss: 1.7873 | Acc (approx): 44.15% | Time: 43.3s\n",
      "Test | Loss: 1.1437 | Acc: 72.57% (7257/10000)\n",
      "   [LR] Current LR = 0.000475\n",
      ">>>> Saved new best model (72.57%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  34 | Loss: 1.7803 | Acc (approx): 44.62% | Time: 44.0s\n",
      "Test | Loss: 1.1217 | Acc: 73.41% (7341/10000)\n",
      "   [LR] Current LR = 0.000473\n",
      ">>>> Saved new best model (73.41%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  35 | Loss: 1.7775 | Acc (approx): 44.78% | Time: 43.8s\n",
      "Test | Loss: 1.1685 | Acc: 71.59% (7159/10000)\n",
      "   [LR] Current LR = 0.000471\n",
      "------------------------------------------------------------\n",
      "Train Epoch  36 | Loss: 1.7563 | Acc (approx): 45.90% | Time: 44.0s\n",
      "Test | Loss: 1.0990 | Acc: 73.72% (7372/10000)\n",
      "   [LR] Current LR = 0.000470\n",
      ">>>> Saved new best model (73.72%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  37 | Loss: 1.7451 | Acc (approx): 46.47% | Time: 43.6s\n",
      "Test | Loss: 1.1552 | Acc: 73.77% (7377/10000)\n",
      "   [LR] Current LR = 0.000468\n",
      ">>>> Saved new best model (73.77%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  38 | Loss: 1.7688 | Acc (approx): 45.39% | Time: 43.8s\n",
      "Test | Loss: 1.1244 | Acc: 74.52% (7452/10000)\n",
      "   [LR] Current LR = 0.000466\n",
      ">>>> Saved new best model (74.52%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  39 | Loss: 1.7596 | Acc (approx): 45.88% | Time: 44.1s\n",
      "Test | Loss: 1.1097 | Acc: 73.66% (7366/10000)\n",
      "   [LR] Current LR = 0.000463\n",
      "------------------------------------------------------------\n",
      "Train Epoch  40 | Loss: 1.7542 | Acc (approx): 46.27% | Time: 44.0s\n",
      "Test | Loss: 1.1018 | Acc: 74.48% (7448/10000)\n",
      "   [LR] Current LR = 0.000461\n",
      "------------------------------------------------------------\n",
      "Train Epoch  41 | Loss: 1.7631 | Acc (approx): 45.49% | Time: 44.2s\n",
      "Test | Loss: 1.1323 | Acc: 73.74% (7374/10000)\n",
      "   [LR] Current LR = 0.000459\n",
      "------------------------------------------------------------\n",
      "Train Epoch  42 | Loss: 1.7528 | Acc (approx): 46.09% | Time: 44.1s\n",
      "Test | Loss: 1.0821 | Acc: 74.79% (7479/10000)\n",
      "   [LR] Current LR = 0.000457\n",
      ">>>> Saved new best model (74.79%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  43 | Loss: 1.7412 | Acc (approx): 46.89% | Time: 44.1s\n",
      "Test | Loss: 1.0919 | Acc: 75.09% (7509/10000)\n",
      "   [LR] Current LR = 0.000455\n",
      ">>>> Saved new best model (75.09%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  44 | Loss: 1.7335 | Acc (approx): 47.15% | Time: 44.4s\n",
      "Test | Loss: 1.0753 | Acc: 75.54% (7554/10000)\n",
      "   [LR] Current LR = 0.000452\n",
      ">>>> Saved new best model (75.54%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  45 | Loss: 1.7263 | Acc (approx): 47.51% | Time: 43.8s\n",
      "Test | Loss: 1.0678 | Acc: 77.28% (7728/10000)\n",
      "   [LR] Current LR = 0.000450\n",
      ">>>> Saved new best model (77.28%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  46 | Loss: 1.7299 | Acc (approx): 47.33% | Time: 44.2s\n",
      "Test | Loss: 1.0679 | Acc: 75.39% (7539/10000)\n",
      "   [LR] Current LR = 0.000448\n",
      "------------------------------------------------------------\n",
      "Train Epoch  47 | Loss: 1.7171 | Acc (approx): 47.95% | Time: 43.8s\n",
      "Test | Loss: 1.0695 | Acc: 76.97% (7697/10000)\n",
      "   [LR] Current LR = 0.000445\n",
      "------------------------------------------------------------\n",
      "Train Epoch  48 | Loss: 1.7220 | Acc (approx): 47.74% | Time: 44.0s\n",
      "Test | Loss: 1.0632 | Acc: 77.20% (7720/10000)\n",
      "   [LR] Current LR = 0.000442\n",
      "------------------------------------------------------------\n",
      "Train Epoch  49 | Loss: 1.7189 | Acc (approx): 47.81% | Time: 44.1s\n",
      "Test | Loss: 1.0359 | Acc: 77.61% (7761/10000)\n",
      "   [LR] Current LR = 0.000440\n",
      ">>>> Saved new best model (77.61%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  50 | Loss: 1.7030 | Acc (approx): 48.71% | Time: 44.0s\n",
      "Test | Loss: 1.0575 | Acc: 78.05% (7805/10000)\n",
      "   [LR] Current LR = 0.000437\n",
      ">>>> Saved new best model (78.05%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  51 | Loss: 1.7102 | Acc (approx): 48.25% | Time: 43.8s\n",
      "Test | Loss: 1.0535 | Acc: 77.19% (7719/10000)\n",
      "   [LR] Current LR = 0.000435\n",
      "------------------------------------------------------------\n",
      "Train Epoch  52 | Loss: 1.7272 | Acc (approx): 47.54% | Time: 43.7s\n",
      "Test | Loss: 1.0158 | Acc: 78.75% (7875/10000)\n",
      "   [LR] Current LR = 0.000432\n",
      ">>>> Saved new best model (78.75%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  53 | Loss: 1.6981 | Acc (approx): 48.94% | Time: 44.0s\n",
      "Test | Loss: 1.0106 | Acc: 78.59% (7859/10000)\n",
      "   [LR] Current LR = 0.000429\n",
      "------------------------------------------------------------\n",
      "Train Epoch  54 | Loss: 1.6824 | Acc (approx): 49.81% | Time: 43.8s\n",
      "Test | Loss: 1.0457 | Acc: 77.73% (7773/10000)\n",
      "   [LR] Current LR = 0.000426\n",
      "------------------------------------------------------------\n",
      "Train Epoch  55 | Loss: 1.6889 | Acc (approx): 49.53% | Time: 43.9s\n",
      "Test | Loss: 1.0119 | Acc: 79.41% (7941/10000)\n",
      "   [LR] Current LR = 0.000423\n",
      ">>>> Saved new best model (79.41%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  56 | Loss: 1.7061 | Acc (approx): 48.58% | Time: 43.9s\n",
      "Test | Loss: 1.0216 | Acc: 78.52% (7852/10000)\n",
      "   [LR] Current LR = 0.000420\n",
      "------------------------------------------------------------\n",
      "Train Epoch  57 | Loss: 1.6725 | Acc (approx): 50.28% | Time: 43.9s\n",
      "Test | Loss: 0.9972 | Acc: 79.00% (7900/10000)\n",
      "   [LR] Current LR = 0.000417\n",
      "------------------------------------------------------------\n",
      "Train Epoch  58 | Loss: 1.6711 | Acc (approx): 50.33% | Time: 44.1s\n",
      "Test | Loss: 0.9952 | Acc: 79.58% (7958/10000)\n",
      "   [LR] Current LR = 0.000414\n",
      ">>>> Saved new best model (79.58%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  59 | Loss: 1.6933 | Acc (approx): 49.05% | Time: 43.7s\n",
      "Test | Loss: 1.0048 | Acc: 79.28% (7928/10000)\n",
      "   [LR] Current LR = 0.000411\n",
      "------------------------------------------------------------\n",
      "Train Epoch  60 | Loss: 1.6871 | Acc (approx): 49.39% | Time: 48.9s\n",
      "Test | Loss: 0.9986 | Acc: 79.22% (7922/10000)\n",
      "   [LR] Current LR = 0.000408\n",
      "------------------------------------------------------------\n",
      "Train Epoch  61 | Loss: 1.6973 | Acc (approx): 49.18% | Time: 55.8s\n",
      "Test | Loss: 1.0044 | Acc: 78.84% (7884/10000)\n",
      "   [LR] Current LR = 0.000405\n",
      "------------------------------------------------------------\n",
      "Train Epoch  62 | Loss: 1.6752 | Acc (approx): 50.18% | Time: 55.8s\n",
      "Test | Loss: 0.9899 | Acc: 80.59% (8059/10000)\n",
      "   [LR] Current LR = 0.000402\n",
      ">>>> Saved new best model (80.59%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  63 | Loss: 1.6489 | Acc (approx): 51.60% | Time: 38.6s\n",
      "Test | Loss: 0.9480 | Acc: 80.90% (8090/10000)\n",
      "   [LR] Current LR = 0.000399\n",
      ">>>> Saved new best model (80.90%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  64 | Loss: 1.6691 | Acc (approx): 50.59% | Time: 38.3s\n",
      "Test | Loss: 0.9731 | Acc: 80.94% (8094/10000)\n",
      "   [LR] Current LR = 0.000396\n",
      ">>>> Saved new best model (80.94%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  65 | Loss: 1.6467 | Acc (approx): 51.58% | Time: 38.1s\n",
      "Test | Loss: 0.9656 | Acc: 80.96% (8096/10000)\n",
      "   [LR] Current LR = 0.000392\n",
      ">>>> Saved new best model (80.96%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  66 | Loss: 1.6756 | Acc (approx): 50.23% | Time: 38.4s\n",
      "Test | Loss: 0.9625 | Acc: 80.66% (8066/10000)\n",
      "   [LR] Current LR = 0.000389\n",
      "------------------------------------------------------------\n",
      "Train Epoch  67 | Loss: 1.6520 | Acc (approx): 51.33% | Time: 38.3s\n",
      "Test | Loss: 0.9679 | Acc: 80.19% (8019/10000)\n",
      "   [LR] Current LR = 0.000386\n",
      "------------------------------------------------------------\n",
      "Train Epoch  68 | Loss: 1.6454 | Acc (approx): 51.72% | Time: 38.4s\n",
      "Test | Loss: 0.9466 | Acc: 81.79% (8179/10000)\n",
      "   [LR] Current LR = 0.000382\n",
      ">>>> Saved new best model (81.79%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  69 | Loss: 1.6560 | Acc (approx): 51.29% | Time: 38.2s\n",
      "Test | Loss: 0.9640 | Acc: 81.43% (8143/10000)\n",
      "   [LR] Current LR = 0.000379\n",
      "------------------------------------------------------------\n",
      "Train Epoch  70 | Loss: 1.6651 | Acc (approx): 50.90% | Time: 38.5s\n",
      "Test | Loss: 0.9509 | Acc: 81.72% (8172/10000)\n",
      "   [LR] Current LR = 0.000375\n",
      "------------------------------------------------------------\n",
      "Train Epoch  71 | Loss: 1.6611 | Acc (approx): 51.07% | Time: 38.3s\n",
      "Test | Loss: 0.9475 | Acc: 82.56% (8256/10000)\n",
      "   [LR] Current LR = 0.000372\n",
      ">>>> Saved new best model (82.56%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  72 | Loss: 1.6445 | Acc (approx): 51.95% | Time: 38.2s\n",
      "Test | Loss: 0.9349 | Acc: 82.17% (8217/10000)\n",
      "   [LR] Current LR = 0.000368\n",
      "------------------------------------------------------------\n",
      "Train Epoch  73 | Loss: 1.6465 | Acc (approx): 51.89% | Time: 38.3s\n",
      "Test | Loss: 0.9289 | Acc: 82.10% (8210/10000)\n",
      "   [LR] Current LR = 0.000365\n",
      "------------------------------------------------------------\n",
      "Train Epoch  74 | Loss: 1.6614 | Acc (approx): 50.75% | Time: 37.9s\n",
      "Test | Loss: 0.9352 | Acc: 81.91% (8191/10000)\n",
      "   [LR] Current LR = 0.000361\n",
      "------------------------------------------------------------\n",
      "Train Epoch  75 | Loss: 1.6396 | Acc (approx): 52.07% | Time: 38.6s\n",
      "Test | Loss: 0.9197 | Acc: 82.96% (8296/10000)\n",
      "   [LR] Current LR = 0.000357\n",
      ">>>> Saved new best model (82.96%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  76 | Loss: 1.6479 | Acc (approx): 51.53% | Time: 38.4s\n",
      "Test | Loss: 0.9138 | Acc: 83.29% (8329/10000)\n",
      "   [LR] Current LR = 0.000354\n",
      ">>>> Saved new best model (83.29%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  77 | Loss: 1.6358 | Acc (approx): 52.15% | Time: 38.5s\n",
      "Test | Loss: 0.9182 | Acc: 82.81% (8281/10000)\n",
      "   [LR] Current LR = 0.000350\n",
      "------------------------------------------------------------\n",
      "Train Epoch  78 | Loss: 1.6293 | Acc (approx): 52.60% | Time: 38.3s\n",
      "Test | Loss: 0.8996 | Acc: 83.60% (8360/10000)\n",
      "   [LR] Current LR = 0.000346\n",
      ">>>> Saved new best model (83.60%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  79 | Loss: 1.6454 | Acc (approx): 51.58% | Time: 38.1s\n",
      "Test | Loss: 0.9069 | Acc: 83.44% (8344/10000)\n",
      "   [LR] Current LR = 0.000343\n",
      "------------------------------------------------------------\n",
      "Train Epoch  80 | Loss: 1.6145 | Acc (approx): 53.48% | Time: 38.4s\n",
      "Test | Loss: 0.9383 | Acc: 81.73% (8173/10000)\n",
      "   [LR] Current LR = 0.000339\n",
      "------------------------------------------------------------\n",
      "Train Epoch  81 | Loss: 1.6219 | Acc (approx): 53.13% | Time: 38.2s\n",
      "Test | Loss: 0.9132 | Acc: 83.78% (8378/10000)\n",
      "   [LR] Current LR = 0.000335\n",
      ">>>> Saved new best model (83.78%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  82 | Loss: 1.6272 | Acc (approx): 52.65% | Time: 38.7s\n",
      "Test | Loss: 0.9134 | Acc: 83.84% (8384/10000)\n",
      "   [LR] Current LR = 0.000331\n",
      ">>>> Saved new best model (83.84%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  83 | Loss: 1.6173 | Acc (approx): 53.16% | Time: 38.5s\n",
      "Test | Loss: 0.8880 | Acc: 83.91% (8391/10000)\n",
      "   [LR] Current LR = 0.000328\n",
      ">>>> Saved new best model (83.91%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  84 | Loss: 1.6241 | Acc (approx): 52.64% | Time: 38.4s\n",
      "Test | Loss: 0.9049 | Acc: 84.31% (8431/10000)\n",
      "   [LR] Current LR = 0.000324\n",
      ">>>> Saved new best model (84.31%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  85 | Loss: 1.6168 | Acc (approx): 53.07% | Time: 38.7s\n",
      "Test | Loss: 0.8850 | Acc: 84.01% (8401/10000)\n",
      "   [LR] Current LR = 0.000320\n",
      "------------------------------------------------------------\n",
      "Train Epoch  86 | Loss: 1.6136 | Acc (approx): 53.39% | Time: 38.4s\n",
      "Test | Loss: 0.8949 | Acc: 84.52% (8452/10000)\n",
      "   [LR] Current LR = 0.000316\n",
      ">>>> Saved new best model (84.52%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  87 | Loss: 1.5935 | Acc (approx): 54.41% | Time: 40.6s\n",
      "Test | Loss: 0.8884 | Acc: 84.09% (8409/10000)\n",
      "   [LR] Current LR = 0.000312\n",
      "------------------------------------------------------------\n",
      "Train Epoch  88 | Loss: 1.6215 | Acc (approx): 52.99% | Time: 51.0s\n",
      "Test | Loss: 0.8687 | Acc: 84.62% (8462/10000)\n",
      "   [LR] Current LR = 0.000308\n",
      ">>>> Saved new best model (84.62%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  89 | Loss: 1.6159 | Acc (approx): 53.21% | Time: 52.7s\n",
      "Test | Loss: 0.8810 | Acc: 84.42% (8442/10000)\n",
      "   [LR] Current LR = 0.000304\n",
      "------------------------------------------------------------\n",
      "Train Epoch  90 | Loss: 1.6000 | Acc (approx): 54.04% | Time: 52.9s\n",
      "Test | Loss: 0.8841 | Acc: 84.51% (8451/10000)\n",
      "   [LR] Current LR = 0.000300\n",
      "------------------------------------------------------------\n",
      "Train Epoch  91 | Loss: 1.5915 | Acc (approx): 54.61% | Time: 38.2s\n",
      "Test | Loss: 0.8779 | Acc: 84.74% (8474/10000)\n",
      "   [LR] Current LR = 0.000296\n",
      ">>>> Saved new best model (84.74%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  92 | Loss: 1.6142 | Acc (approx): 53.43% | Time: 38.4s\n",
      "Test | Loss: 0.8911 | Acc: 84.44% (8444/10000)\n",
      "   [LR] Current LR = 0.000293\n",
      "------------------------------------------------------------\n",
      "Train Epoch  93 | Loss: 1.5925 | Acc (approx): 54.40% | Time: 38.5s\n",
      "Test | Loss: 0.8767 | Acc: 84.52% (8452/10000)\n",
      "   [LR] Current LR = 0.000289\n",
      "------------------------------------------------------------\n",
      "Train Epoch  94 | Loss: 1.6079 | Acc (approx): 53.66% | Time: 38.3s\n",
      "Test | Loss: 0.8769 | Acc: 84.61% (8461/10000)\n",
      "   [LR] Current LR = 0.000285\n",
      "------------------------------------------------------------\n",
      "Train Epoch  95 | Loss: 1.6055 | Acc (approx): 53.83% | Time: 38.5s\n",
      "Test | Loss: 0.8802 | Acc: 84.70% (8470/10000)\n",
      "   [LR] Current LR = 0.000281\n",
      "------------------------------------------------------------\n",
      "Train Epoch  96 | Loss: 1.5719 | Acc (approx): 55.35% | Time: 38.4s\n",
      "Test | Loss: 0.8812 | Acc: 84.46% (8446/10000)\n",
      "   [LR] Current LR = 0.000277\n",
      "------------------------------------------------------------\n",
      "Train Epoch  97 | Loss: 1.6102 | Acc (approx): 53.37% | Time: 38.5s\n",
      "Test | Loss: 0.8618 | Acc: 85.69% (8569/10000)\n",
      "   [LR] Current LR = 0.000273\n",
      ">>>> Saved new best model (85.69%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch  98 | Loss: 1.5777 | Acc (approx): 55.15% | Time: 38.4s\n",
      "Test | Loss: 0.8738 | Acc: 85.23% (8523/10000)\n",
      "   [LR] Current LR = 0.000269\n",
      "------------------------------------------------------------\n",
      "Train Epoch  99 | Loss: 1.5685 | Acc (approx): 55.44% | Time: 38.7s\n",
      "Test | Loss: 0.8719 | Acc: 84.63% (8463/10000)\n",
      "   [LR] Current LR = 0.000265\n",
      "------------------------------------------------------------\n",
      "Train Epoch 100 | Loss: 1.5752 | Acc (approx): 54.98% | Time: 38.5s\n",
      "Test | Loss: 0.8596 | Acc: 85.59% (8559/10000)\n",
      "   [LR] Current LR = 0.000261\n",
      "------------------------------------------------------------\n",
      "Train Epoch 101 | Loss: 1.5810 | Acc (approx): 54.87% | Time: 38.4s\n",
      "Test | Loss: 0.8480 | Acc: 85.46% (8546/10000)\n",
      "   [LR] Current LR = 0.000257\n",
      "------------------------------------------------------------\n",
      "Train Epoch 102 | Loss: 1.5860 | Acc (approx): 54.73% | Time: 38.3s\n",
      "Test | Loss: 0.8528 | Acc: 86.07% (8607/10000)\n",
      "   [LR] Current LR = 0.000253\n",
      ">>>> Saved new best model (86.07%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 103 | Loss: 1.5619 | Acc (approx): 55.81% | Time: 38.3s\n",
      "Test | Loss: 0.8318 | Acc: 86.18% (8618/10000)\n",
      "   [LR] Current LR = 0.000248\n",
      ">>>> Saved new best model (86.18%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 104 | Loss: 1.5594 | Acc (approx): 56.19% | Time: 38.6s\n",
      "Test | Loss: 0.8641 | Acc: 85.49% (8549/10000)\n",
      "   [LR] Current LR = 0.000244\n",
      "------------------------------------------------------------\n",
      "Train Epoch 105 | Loss: 1.6026 | Acc (approx): 53.96% | Time: 38.5s\n",
      "Test | Loss: 0.8320 | Acc: 86.28% (8628/10000)\n",
      "   [LR] Current LR = 0.000240\n",
      ">>>> Saved new best model (86.28%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 106 | Loss: 1.5489 | Acc (approx): 56.40% | Time: 38.3s\n",
      "Test | Loss: 0.8400 | Acc: 86.10% (8610/10000)\n",
      "   [LR] Current LR = 0.000236\n",
      "------------------------------------------------------------\n",
      "Train Epoch 107 | Loss: 1.5748 | Acc (approx): 55.45% | Time: 38.5s\n",
      "Test | Loss: 0.8400 | Acc: 86.45% (8645/10000)\n",
      "   [LR] Current LR = 0.000232\n",
      ">>>> Saved new best model (86.45%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 108 | Loss: 1.5754 | Acc (approx): 55.12% | Time: 38.5s\n",
      "Test | Loss: 0.8604 | Acc: 85.96% (8596/10000)\n",
      "   [LR] Current LR = 0.000228\n",
      "------------------------------------------------------------\n",
      "Train Epoch 109 | Loss: 1.5660 | Acc (approx): 55.63% | Time: 38.5s\n",
      "Test | Loss: 0.8472 | Acc: 86.33% (8633/10000)\n",
      "   [LR] Current LR = 0.000224\n",
      "------------------------------------------------------------\n",
      "Train Epoch 110 | Loss: 1.5436 | Acc (approx): 56.87% | Time: 38.5s\n",
      "Test | Loss: 0.8321 | Acc: 86.52% (8652/10000)\n",
      "   [LR] Current LR = 0.000220\n",
      ">>>> Saved new best model (86.52%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 111 | Loss: 1.5660 | Acc (approx): 55.81% | Time: 38.4s\n",
      "Test | Loss: 0.8405 | Acc: 86.20% (8620/10000)\n",
      "   [LR] Current LR = 0.000216\n",
      "------------------------------------------------------------\n",
      "Train Epoch 112 | Loss: 1.5692 | Acc (approx): 55.64% | Time: 31.1s\n",
      "Test | Loss: 0.8164 | Acc: 86.69% (8669/10000)\n",
      "   [LR] Current LR = 0.000212\n",
      ">>>> Saved new best model (86.69%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 113 | Loss: 1.5630 | Acc (approx): 55.60% | Time: 22.1s\n",
      "Test | Loss: 0.8283 | Acc: 86.79% (8679/10000)\n",
      "   [LR] Current LR = 0.000208\n",
      ">>>> Saved new best model (86.79%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 114 | Loss: 1.5503 | Acc (approx): 56.23% | Time: 21.9s\n",
      "Test | Loss: 0.8299 | Acc: 86.96% (8696/10000)\n",
      "   [LR] Current LR = 0.000205\n",
      ">>>> Saved new best model (86.96%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 115 | Loss: 1.5539 | Acc (approx): 56.22% | Time: 21.1s\n",
      "Test | Loss: 0.8285 | Acc: 86.59% (8659/10000)\n",
      "   [LR] Current LR = 0.000201\n",
      "------------------------------------------------------------\n",
      "Train Epoch 116 | Loss: 1.5532 | Acc (approx): 56.26% | Time: 21.3s\n",
      "Test | Loss: 0.8416 | Acc: 86.66% (8666/10000)\n",
      "   [LR] Current LR = 0.000197\n",
      "------------------------------------------------------------\n",
      "Train Epoch 117 | Loss: 1.5532 | Acc (approx): 56.35% | Time: 20.9s\n",
      "Test | Loss: 0.8260 | Acc: 87.01% (8701/10000)\n",
      "   [LR] Current LR = 0.000193\n",
      ">>>> Saved new best model (87.01%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 118 | Loss: 1.5397 | Acc (approx): 57.11% | Time: 21.4s\n",
      "Test | Loss: 0.8289 | Acc: 86.43% (8643/10000)\n",
      "   [LR] Current LR = 0.000189\n",
      "------------------------------------------------------------\n",
      "Train Epoch 119 | Loss: 1.5352 | Acc (approx): 57.18% | Time: 22.5s\n",
      "Test | Loss: 0.8194 | Acc: 87.18% (8718/10000)\n",
      "   [LR] Current LR = 0.000185\n",
      ">>>> Saved new best model (87.18%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 120 | Loss: 1.5676 | Acc (approx): 55.54% | Time: 20.4s\n",
      "Test | Loss: 0.8130 | Acc: 87.66% (8766/10000)\n",
      "   [LR] Current LR = 0.000181\n",
      ">>>> Saved new best model (87.66%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 121 | Loss: 1.5512 | Acc (approx): 56.55% | Time: 21.7s\n",
      "Test | Loss: 0.8306 | Acc: 86.54% (8654/10000)\n",
      "   [LR] Current LR = 0.000177\n",
      "------------------------------------------------------------\n",
      "Train Epoch 122 | Loss: 1.5412 | Acc (approx): 56.84% | Time: 21.5s\n",
      "Test | Loss: 0.8081 | Acc: 87.64% (8764/10000)\n",
      "   [LR] Current LR = 0.000173\n",
      "------------------------------------------------------------\n",
      "Train Epoch 123 | Loss: 1.5645 | Acc (approx): 55.72% | Time: 20.8s\n",
      "Test | Loss: 0.8135 | Acc: 87.62% (8762/10000)\n",
      "   [LR] Current LR = 0.000170\n",
      "------------------------------------------------------------\n",
      "Train Epoch 124 | Loss: 1.5448 | Acc (approx): 56.60% | Time: 21.5s\n",
      "Test | Loss: 0.8077 | Acc: 88.02% (8802/10000)\n",
      "   [LR] Current LR = 0.000166\n",
      ">>>> Saved new best model (88.02%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 125 | Loss: 1.5505 | Acc (approx): 56.16% | Time: 21.0s\n",
      "Test | Loss: 0.8074 | Acc: 87.95% (8795/10000)\n",
      "   [LR] Current LR = 0.000162\n",
      "------------------------------------------------------------\n",
      "Train Epoch 126 | Loss: 1.5358 | Acc (approx): 56.87% | Time: 21.5s\n",
      "Test | Loss: 0.7868 | Acc: 87.74% (8774/10000)\n",
      "   [LR] Current LR = 0.000158\n",
      "------------------------------------------------------------\n",
      "Train Epoch 127 | Loss: 1.5200 | Acc (approx): 57.84% | Time: 22.0s\n",
      "Test | Loss: 0.7945 | Acc: 88.01% (8801/10000)\n",
      "   [LR] Current LR = 0.000155\n",
      "------------------------------------------------------------\n",
      "Train Epoch 128 | Loss: 1.5522 | Acc (approx): 56.21% | Time: 21.6s\n",
      "Test | Loss: 0.8137 | Acc: 87.78% (8778/10000)\n",
      "   [LR] Current LR = 0.000151\n",
      "------------------------------------------------------------\n",
      "Train Epoch 129 | Loss: 1.5352 | Acc (approx): 57.33% | Time: 21.3s\n",
      "Test | Loss: 0.8069 | Acc: 87.88% (8788/10000)\n",
      "   [LR] Current LR = 0.000147\n",
      "------------------------------------------------------------\n",
      "Train Epoch 130 | Loss: 1.5479 | Acc (approx): 56.52% | Time: 20.4s\n",
      "Test | Loss: 0.7960 | Acc: 88.35% (8835/10000)\n",
      "   [LR] Current LR = 0.000144\n",
      ">>>> Saved new best model (88.35%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 131 | Loss: 1.5113 | Acc (approx): 58.40% | Time: 21.0s\n",
      "Test | Loss: 0.7972 | Acc: 88.12% (8812/10000)\n",
      "   [LR] Current LR = 0.000140\n",
      "------------------------------------------------------------\n",
      "Train Epoch 132 | Loss: 1.5231 | Acc (approx): 57.77% | Time: 20.8s\n",
      "Test | Loss: 0.7943 | Acc: 88.18% (8818/10000)\n",
      "   [LR] Current LR = 0.000136\n",
      "------------------------------------------------------------\n",
      "Train Epoch 133 | Loss: 1.5199 | Acc (approx): 57.82% | Time: 21.8s\n",
      "Test | Loss: 0.7823 | Acc: 88.11% (8811/10000)\n",
      "   [LR] Current LR = 0.000133\n",
      "------------------------------------------------------------\n",
      "Train Epoch 134 | Loss: 1.5499 | Acc (approx): 56.32% | Time: 22.2s\n",
      "Test | Loss: 0.7922 | Acc: 88.61% (8861/10000)\n",
      "   [LR] Current LR = 0.000129\n",
      ">>>> Saved new best model (88.61%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 135 | Loss: 1.5275 | Acc (approx): 57.23% | Time: 21.6s\n",
      "Test | Loss: 0.7945 | Acc: 88.55% (8855/10000)\n",
      "   [LR] Current LR = 0.000126\n",
      "------------------------------------------------------------\n",
      "Train Epoch 136 | Loss: 1.5242 | Acc (approx): 57.46% | Time: 21.0s\n",
      "Test | Loss: 0.8005 | Acc: 88.36% (8836/10000)\n",
      "   [LR] Current LR = 0.000122\n",
      "------------------------------------------------------------\n",
      "Train Epoch 137 | Loss: 1.5013 | Acc (approx): 58.64% | Time: 21.1s\n",
      "Test | Loss: 0.7997 | Acc: 88.53% (8853/10000)\n",
      "   [LR] Current LR = 0.000119\n",
      "------------------------------------------------------------\n",
      "Train Epoch 138 | Loss: 1.5156 | Acc (approx): 58.03% | Time: 21.2s\n",
      "Test | Loss: 0.7690 | Acc: 88.90% (8890/10000)\n",
      "   [LR] Current LR = 0.000115\n",
      ">>>> Saved new best model (88.90%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 139 | Loss: 1.5279 | Acc (approx): 57.39% | Time: 20.8s\n",
      "Test | Loss: 0.7913 | Acc: 88.92% (8892/10000)\n",
      "   [LR] Current LR = 0.000112\n",
      ">>>> Saved new best model (88.92%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 140 | Loss: 1.5164 | Acc (approx): 57.88% | Time: 21.4s\n",
      "Test | Loss: 0.7821 | Acc: 88.64% (8864/10000)\n",
      "   [LR] Current LR = 0.000109\n",
      "------------------------------------------------------------\n",
      "Train Epoch 141 | Loss: 1.5069 | Acc (approx): 58.29% | Time: 20.8s\n",
      "Test | Loss: 0.7785 | Acc: 88.59% (8859/10000)\n",
      "   [LR] Current LR = 0.000105\n",
      "------------------------------------------------------------\n",
      "Train Epoch 142 | Loss: 1.5153 | Acc (approx): 58.03% | Time: 20.6s\n",
      "Test | Loss: 0.7977 | Acc: 88.69% (8869/10000)\n",
      "   [LR] Current LR = 0.000102\n",
      "------------------------------------------------------------\n",
      "Train Epoch 143 | Loss: 1.4949 | Acc (approx): 58.86% | Time: 20.8s\n",
      "Test | Loss: 0.7652 | Acc: 89.32% (8932/10000)\n",
      "   [LR] Current LR = 0.000099\n",
      ">>>> Saved new best model (89.32%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 144 | Loss: 1.5072 | Acc (approx): 58.52% | Time: 20.8s\n",
      "Test | Loss: 0.7882 | Acc: 89.11% (8911/10000)\n",
      "   [LR] Current LR = 0.000096\n",
      "------------------------------------------------------------\n",
      "Train Epoch 145 | Loss: 1.5066 | Acc (approx): 58.28% | Time: 21.6s\n",
      "Test | Loss: 0.7759 | Acc: 89.01% (8901/10000)\n",
      "   [LR] Current LR = 0.000093\n",
      "------------------------------------------------------------\n",
      "Train Epoch 146 | Loss: 1.5065 | Acc (approx): 58.31% | Time: 21.5s\n",
      "Test | Loss: 0.7797 | Acc: 88.94% (8894/10000)\n",
      "   [LR] Current LR = 0.000090\n",
      "------------------------------------------------------------\n",
      "Train Epoch 147 | Loss: 1.4996 | Acc (approx): 58.88% | Time: 21.5s\n",
      "Test | Loss: 0.7747 | Acc: 89.25% (8925/10000)\n",
      "   [LR] Current LR = 0.000087\n",
      "------------------------------------------------------------\n",
      "Train Epoch 148 | Loss: 1.5095 | Acc (approx): 58.21% | Time: 21.1s\n",
      "Test | Loss: 0.7886 | Acc: 89.31% (8931/10000)\n",
      "   [LR] Current LR = 0.000084\n",
      "------------------------------------------------------------\n",
      "Train Epoch 149 | Loss: 1.5107 | Acc (approx): 58.20% | Time: 21.6s\n",
      "Test | Loss: 0.7809 | Acc: 89.12% (8912/10000)\n",
      "   [LR] Current LR = 0.000081\n",
      "------------------------------------------------------------\n",
      "Train Epoch 150 | Loss: 1.4701 | Acc (approx): 60.23% | Time: 20.8s\n",
      "Test | Loss: 0.7650 | Acc: 89.41% (8941/10000)\n",
      "   [LR] Current LR = 0.000078\n",
      ">>>> Saved new best model (89.41%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 151 | Loss: 1.5074 | Acc (approx): 58.29% | Time: 22.1s\n",
      "Test | Loss: 0.7656 | Acc: 89.34% (8934/10000)\n",
      "   [LR] Current LR = 0.000075\n",
      "------------------------------------------------------------\n",
      "Train Epoch 152 | Loss: 1.5138 | Acc (approx): 57.85% | Time: 21.8s\n",
      "Test | Loss: 0.7684 | Acc: 89.25% (8925/10000)\n",
      "   [LR] Current LR = 0.000072\n",
      "------------------------------------------------------------\n",
      "Train Epoch 153 | Loss: 1.5056 | Acc (approx): 58.19% | Time: 21.7s\n",
      "Test | Loss: 0.7760 | Acc: 89.32% (8932/10000)\n",
      "   [LR] Current LR = 0.000069\n",
      "------------------------------------------------------------\n",
      "Train Epoch 154 | Loss: 1.5230 | Acc (approx): 57.72% | Time: 21.5s\n",
      "Test | Loss: 0.7841 | Acc: 89.11% (8911/10000)\n",
      "   [LR] Current LR = 0.000066\n",
      "------------------------------------------------------------\n",
      "Train Epoch 155 | Loss: 1.4917 | Acc (approx): 58.96% | Time: 21.3s\n",
      "Test | Loss: 0.7656 | Acc: 89.46% (8946/10000)\n",
      "   [LR] Current LR = 0.000064\n",
      ">>>> Saved new best model (89.46%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 156 | Loss: 1.4756 | Acc (approx): 59.74% | Time: 21.1s\n",
      "Test | Loss: 0.7704 | Acc: 89.15% (8915/10000)\n",
      "   [LR] Current LR = 0.000061\n",
      "------------------------------------------------------------\n",
      "Train Epoch 157 | Loss: 1.4941 | Acc (approx): 59.01% | Time: 21.7s\n",
      "Test | Loss: 0.7602 | Acc: 89.53% (8953/10000)\n",
      "   [LR] Current LR = 0.000059\n",
      ">>>> Saved new best model (89.53%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 158 | Loss: 1.5130 | Acc (approx): 58.11% | Time: 21.1s\n",
      "Test | Loss: 0.7641 | Acc: 89.54% (8954/10000)\n",
      "   [LR] Current LR = 0.000056\n",
      ">>>> Saved new best model (89.54%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 159 | Loss: 1.5108 | Acc (approx): 58.26% | Time: 20.1s\n",
      "Test | Loss: 0.7688 | Acc: 89.46% (8946/10000)\n",
      "   [LR] Current LR = 0.000053\n",
      "------------------------------------------------------------\n",
      "Train Epoch 160 | Loss: 1.5101 | Acc (approx): 58.21% | Time: 21.2s\n",
      "Test | Loss: 0.7779 | Acc: 89.31% (8931/10000)\n",
      "   [LR] Current LR = 0.000051\n",
      "------------------------------------------------------------\n",
      "Train Epoch 161 | Loss: 1.5191 | Acc (approx): 57.81% | Time: 20.0s\n",
      "Test | Loss: 0.7535 | Acc: 89.81% (8981/10000)\n",
      "   [LR] Current LR = 0.000049\n",
      ">>>> Saved new best model (89.81%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 162 | Loss: 1.4825 | Acc (approx): 59.52% | Time: 21.6s\n",
      "Test | Loss: 0.7648 | Acc: 89.57% (8957/10000)\n",
      "   [LR] Current LR = 0.000046\n",
      "------------------------------------------------------------\n",
      "Train Epoch 163 | Loss: 1.4459 | Acc (approx): 61.20% | Time: 21.4s\n",
      "Test | Loss: 0.7633 | Acc: 89.40% (8940/10000)\n",
      "   [LR] Current LR = 0.000044\n",
      "------------------------------------------------------------\n",
      "Train Epoch 164 | Loss: 1.4759 | Acc (approx): 59.74% | Time: 21.1s\n",
      "Test | Loss: 0.7604 | Acc: 89.80% (8980/10000)\n",
      "   [LR] Current LR = 0.000042\n",
      "------------------------------------------------------------\n",
      "Train Epoch 165 | Loss: 1.4752 | Acc (approx): 59.74% | Time: 20.7s\n",
      "Test | Loss: 0.7562 | Acc: 89.56% (8956/10000)\n",
      "   [LR] Current LR = 0.000040\n",
      "------------------------------------------------------------\n",
      "Train Epoch 166 | Loss: 1.4945 | Acc (approx): 58.65% | Time: 20.8s\n",
      "Test | Loss: 0.7552 | Acc: 89.63% (8963/10000)\n",
      "   [LR] Current LR = 0.000038\n",
      "------------------------------------------------------------\n",
      "Train Epoch 167 | Loss: 1.4647 | Acc (approx): 60.19% | Time: 21.3s\n",
      "Test | Loss: 0.7554 | Acc: 89.58% (8958/10000)\n",
      "   [LR] Current LR = 0.000035\n",
      "------------------------------------------------------------\n",
      "Train Epoch 168 | Loss: 1.4838 | Acc (approx): 59.23% | Time: 21.0s\n",
      "Test | Loss: 0.7587 | Acc: 89.79% (8979/10000)\n",
      "   [LR] Current LR = 0.000033\n",
      "------------------------------------------------------------\n",
      "Train Epoch 169 | Loss: 1.4607 | Acc (approx): 60.20% | Time: 21.4s\n",
      "Test | Loss: 0.7598 | Acc: 89.83% (8983/10000)\n",
      "   [LR] Current LR = 0.000031\n",
      ">>>> Saved new best model (89.83%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 170 | Loss: 1.4939 | Acc (approx): 58.94% | Time: 22.9s\n",
      "Test | Loss: 0.7587 | Acc: 89.91% (8991/10000)\n",
      "   [LR] Current LR = 0.000030\n",
      ">>>> Saved new best model (89.91%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 171 | Loss: 1.4694 | Acc (approx): 60.15% | Time: 21.8s\n",
      "Test | Loss: 0.7560 | Acc: 89.92% (8992/10000)\n",
      "   [LR] Current LR = 0.000028\n",
      ">>>> Saved new best model (89.92%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 172 | Loss: 1.4904 | Acc (approx): 58.86% | Time: 20.9s\n",
      "Test | Loss: 0.7561 | Acc: 89.91% (8991/10000)\n",
      "   [LR] Current LR = 0.000026\n",
      "------------------------------------------------------------\n",
      "Train Epoch 173 | Loss: 1.4726 | Acc (approx): 59.78% | Time: 21.1s\n",
      "Test | Loss: 0.7582 | Acc: 89.84% (8984/10000)\n",
      "   [LR] Current LR = 0.000024\n",
      "------------------------------------------------------------\n",
      "Train Epoch 174 | Loss: 1.4898 | Acc (approx): 59.35% | Time: 21.0s\n",
      "Test | Loss: 0.7551 | Acc: 89.88% (8988/10000)\n",
      "   [LR] Current LR = 0.000023\n",
      "------------------------------------------------------------\n",
      "Train Epoch 175 | Loss: 1.4732 | Acc (approx): 59.97% | Time: 21.6s\n",
      "Test | Loss: 0.7584 | Acc: 90.00% (9000/10000)\n",
      "   [LR] Current LR = 0.000021\n",
      ">>>> Saved new best model (90.00%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 176 | Loss: 1.4613 | Acc (approx): 60.50% | Time: 20.7s\n",
      "Test | Loss: 0.7551 | Acc: 90.05% (9005/10000)\n",
      "   [LR] Current LR = 0.000019\n",
      ">>>> Saved new best model (90.05%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 177 | Loss: 1.4676 | Acc (approx): 60.31% | Time: 20.6s\n",
      "Test | Loss: 0.7543 | Acc: 90.00% (9000/10000)\n",
      "   [LR] Current LR = 0.000018\n",
      "------------------------------------------------------------\n",
      "Train Epoch 178 | Loss: 1.4713 | Acc (approx): 59.87% | Time: 21.6s\n",
      "Test | Loss: 0.7506 | Acc: 90.02% (9002/10000)\n",
      "   [LR] Current LR = 0.000017\n",
      "------------------------------------------------------------\n",
      "Train Epoch 179 | Loss: 1.4908 | Acc (approx): 58.88% | Time: 22.1s\n",
      "Test | Loss: 0.7561 | Acc: 90.09% (9009/10000)\n",
      "   [LR] Current LR = 0.000015\n",
      ">>>> Saved new best model (90.09%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 180 | Loss: 1.4748 | Acc (approx): 60.09% | Time: 21.4s\n",
      "Test | Loss: 0.7532 | Acc: 89.95% (8995/10000)\n",
      "   [LR] Current LR = 0.000014\n",
      "------------------------------------------------------------\n",
      "Train Epoch 181 | Loss: 1.4771 | Acc (approx): 59.78% | Time: 21.1s\n",
      "Test | Loss: 0.7529 | Acc: 90.10% (9010/10000)\n",
      "   [LR] Current LR = 0.000013\n",
      ">>>> Saved new best model (90.10%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 182 | Loss: 1.4901 | Acc (approx): 59.33% | Time: 21.3s\n",
      "Test | Loss: 0.7551 | Acc: 90.06% (9006/10000)\n",
      "   [LR] Current LR = 0.000011\n",
      "------------------------------------------------------------\n",
      "Train Epoch 183 | Loss: 1.4578 | Acc (approx): 60.56% | Time: 21.7s\n",
      "Test | Loss: 0.7504 | Acc: 90.15% (9015/10000)\n",
      "   [LR] Current LR = 0.000010\n",
      ">>>> Saved new best model (90.15%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 184 | Loss: 1.4578 | Acc (approx): 60.45% | Time: 21.4s\n",
      "Test | Loss: 0.7443 | Acc: 90.15% (9015/10000)\n",
      "   [LR] Current LR = 0.000009\n",
      "------------------------------------------------------------\n",
      "Train Epoch 185 | Loss: 1.4861 | Acc (approx): 59.27% | Time: 21.8s\n",
      "Test | Loss: 0.7530 | Acc: 90.06% (9006/10000)\n",
      "   [LR] Current LR = 0.000008\n",
      "------------------------------------------------------------\n",
      "Train Epoch 186 | Loss: 1.4773 | Acc (approx): 59.53% | Time: 21.3s\n",
      "Test | Loss: 0.7529 | Acc: 90.06% (9006/10000)\n",
      "   [LR] Current LR = 0.000007\n",
      "------------------------------------------------------------\n",
      "Train Epoch 187 | Loss: 1.4601 | Acc (approx): 60.66% | Time: 21.7s\n",
      "Test | Loss: 0.7501 | Acc: 90.07% (9007/10000)\n",
      "   [LR] Current LR = 0.000006\n",
      "------------------------------------------------------------\n",
      "Train Epoch 188 | Loss: 1.4716 | Acc (approx): 59.94% | Time: 21.3s\n",
      "Test | Loss: 0.7477 | Acc: 89.98% (8998/10000)\n",
      "   [LR] Current LR = 0.000006\n",
      "------------------------------------------------------------\n",
      "Train Epoch 189 | Loss: 1.4552 | Acc (approx): 60.63% | Time: 21.7s\n",
      "Test | Loss: 0.7496 | Acc: 90.04% (9004/10000)\n",
      "   [LR] Current LR = 0.000005\n",
      "------------------------------------------------------------\n",
      "Train Epoch 190 | Loss: 1.4529 | Acc (approx): 60.74% | Time: 21.9s\n",
      "Test | Loss: 0.7482 | Acc: 90.08% (9008/10000)\n",
      "   [LR] Current LR = 0.000004\n",
      "------------------------------------------------------------\n",
      "Train Epoch 191 | Loss: 1.4751 | Acc (approx): 59.79% | Time: 21.7s\n",
      "Test | Loss: 0.7505 | Acc: 90.13% (9013/10000)\n",
      "   [LR] Current LR = 0.000004\n",
      "------------------------------------------------------------\n",
      "Train Epoch 192 | Loss: 1.4604 | Acc (approx): 60.35% | Time: 21.2s\n",
      "Test | Loss: 0.7493 | Acc: 90.21% (9021/10000)\n",
      "   [LR] Current LR = 0.000003\n",
      ">>>> Saved new best model (90.21%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 193 | Loss: 1.4696 | Acc (approx): 59.84% | Time: 23.2s\n",
      "Test | Loss: 0.7510 | Acc: 90.07% (9007/10000)\n",
      "   [LR] Current LR = 0.000003\n",
      "------------------------------------------------------------\n",
      "Train Epoch 194 | Loss: 1.4400 | Acc (approx): 61.58% | Time: 22.7s\n",
      "Test | Loss: 0.7467 | Acc: 90.21% (9021/10000)\n",
      "   [LR] Current LR = 0.000002\n",
      "------------------------------------------------------------\n",
      "Train Epoch 195 | Loss: 1.4545 | Acc (approx): 60.70% | Time: 21.7s\n",
      "Test | Loss: 0.7476 | Acc: 90.16% (9016/10000)\n",
      "   [LR] Current LR = 0.000002\n",
      "------------------------------------------------------------\n",
      "Train Epoch 196 | Loss: 1.4769 | Acc (approx): 59.79% | Time: 21.5s\n",
      "Test | Loss: 0.7498 | Acc: 90.23% (9023/10000)\n",
      "   [LR] Current LR = 0.000002\n",
      ">>>> Saved new best model (90.23%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 197 | Loss: 1.4539 | Acc (approx): 60.55% | Time: 21.5s\n",
      "Test | Loss: 0.7484 | Acc: 90.33% (9033/10000)\n",
      "   [LR] Current LR = 0.000001\n",
      ">>>> Saved new best model (90.33%) <<<<\n",
      "------------------------------------------------------------\n",
      "Train Epoch 198 | Loss: 1.4612 | Acc (approx): 60.18% | Time: 21.8s\n",
      "Test | Loss: 0.7482 | Acc: 90.27% (9027/10000)\n",
      "   [LR] Current LR = 0.000001\n",
      "------------------------------------------------------------\n",
      "Train Epoch 199 | Loss: 1.4690 | Acc (approx): 60.05% | Time: 21.2s\n",
      "Test | Loss: 0.7484 | Acc: 90.26% (9026/10000)\n",
      "   [LR] Current LR = 0.000001\n",
      "------------------------------------------------------------\n",
      "Train Epoch 200 | Loss: 1.4691 | Acc (approx): 60.04% | Time: 21.6s\n",
      "Test | Loss: 0.7483 | Acc: 90.29% (9029/10000)\n",
      "   [LR] Current LR = 0.000001\n",
      "------------------------------------------------------------\n",
      "Training finished. Best Acc: 90.33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 步骤 8: 模型实例化和主训练循环\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# --- Swin Transformer 配置 ---\n",
    "swin_config = {\n",
    "    \"img_size\": 32,\n",
    "    \"patch_size\": 2,        \n",
    "    \"in_chans\": 3,\n",
    "    \"num_classes\": 10,\n",
    "    \"embed_dim\": 96,        \n",
    "    \"depths\": [2, 2, 6, 2], \n",
    "    \"num_heads\": [3, 6, 12, 24],\n",
    "    \"window_size\": 4,       \n",
    "    \"drop_path_rate\": 0.2,\n",
    "    \"drop_rate\": 0.1,       \n",
    "    \"attn_drop_rate\": 0.0,\n",
    "}\n",
    "\n",
    "# 实例化 Swin Transformer 模型\n",
    "swin_net = SwinTransformer(**swin_config).to(DEVICE)\n",
    "print(f\"--- 实例化 Swin Transformer (Swin-T) ---\")\n",
    "print(swin_net)\n",
    "\n",
    "# 优化器: AdamW\n",
    "optimizer_swin = optim.AdamW(swin_net.parameters(), lr=BASE_LR, weight_decay=0.05)\n",
    "\n",
    "\n",
    "# 学习率调度器设置\n",
    "scheduler_main = CosineAnnealingLR(\n",
    "    optimizer_swin, \n",
    "    T_max=NUM_TOTAL_EPOCHS - NUM_WARMUP_EPOCHS, \n",
    "    eta_min=1e-6 # 最小学习率\n",
    ")\n",
    "\n",
    "scheduler_warmup = LinearWarmup(optimizer_swin, warmup_epochs=NUM_WARMUP_EPOCHS)\n",
    "\n",
    "\n",
    "# --- Main Loop ---\n",
    "best_acc = 0\n",
    "print(f\"\\n--- 开始 {NUM_TOTAL_EPOCHS} 轮 Swin Transformer 训练 ---\")\n",
    "\n",
    "for epoch in range(NUM_TOTAL_EPOCHS):\n",
    "    # 训练步骤\n",
    "    train(epoch, swin_net, trainloader, optimizer_swin, criterion) \n",
    "    # 测试步骤\n",
    "    acc = test(epoch, swin_net, testloader, criterion)\n",
    "    # 学习率更新逻辑\n",
    "    if epoch < NUM_WARMUP_EPOCHS:\n",
    "        scheduler_warmup.step()\n",
    "    else:\n",
    "        scheduler_main.step() \n",
    "    current_lr = optimizer_swin.param_groups[0]['lr']\n",
    "    print(f\"   [LR] Current LR = {current_lr:.6f}\")\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(swin_net.state_dict(), \"swin_transformer_sota_best.pth\")\n",
    "        print(f\">>>> Saved new best model ({best_acc:.2f}%) <<<<\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"Training finished. Best Acc:\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a735bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a1c0116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.9802322e-08..0.96862745].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.9802322e-08..0.827451].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.9802322e-08..1.0].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "def visualize_predictions(net, loader, num_images=10):\n",
    "    net.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    with torch.no_grad():\n",
    "        # 从测试数据加载器中获取一个批次\n",
    "        dataiter = iter(loader)\n",
    "        images, labels = next(dataiter)\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for i in range(images.size(0)):\n",
    "            if images_so_far >= num_images:\n",
    "                break\n",
    "            images_so_far += 1\n",
    "            ax = plt.subplot(num_images // 5, 5, images_so_far)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f'predicted: {classes[preds[i]]}\\n(true: {classes[labels[i]]})')\n",
    "            # 反标准化并显示图像\n",
    "            img = images[i].cpu()\n",
    "            img[0] = img[0] * 0.2023 + 0.4914\n",
    "            img[1] = img[1] * 0.1994 + 0.4822\n",
    "            img[2] = img[2] * 0.2010 + 0.4465\n",
    "            npimg = img.numpy()\n",
    "            plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "# 使用训练好的优化模型进行可视化\n",
    "visualize_predictions(swin_net, testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
