
### **实验报告三：方法改进与优化**

在完成基准实验的基础上，我们为了提升模型的分割性能和训练过程的有效性，引入了一系列先进的方法论进行改进。这些改进主要集中在**数据增强策略、模型训练与优化、以及性能评估与模型选择**三个方面。

#### **一、 数据处理与增强策略的深化**

基准实验采用了一套有效的基础数据增强流程，包括随机缩放、随机裁剪和随机水平翻转。我们在实现这一流程的同时，识别出可以进一步提升模型泛化能力的增强策略。

*   **基准方法**：
    1.  **随机尺寸缩放**：将图像按0.5到2.0之间的随机比例进行缩放。
    2.  **随机裁剪**：从缩放后的图像中随机裁剪出513x513大小的图像块用于训练。
    3.  **随机水平翻转**：以50%的概率对图像和掩码进行水平翻bling。

*   **我们的改进与思考**：
    我们认为，为了让模型在更复杂的真实场景下表现稳健，还需要引入对色彩和角度变化的适应性。因此，提出以下两种可融入流程的增强方法：
    1.  **色彩抖动 (Color Jittering)**：在训练过程中，随机改变输入图像的**亮度、对比度、饱和度和色调**。这一改进能显著降低模型对特定光照条件的依赖，使其在不同光线环境下（如过曝、欠曝、黄昏）都能做出更准确的分割。
    2.  **随机旋转 (Random Rotation)**：在小角度范围内（如-15到+15度）对图像和掩码进行随机旋转。这能提升模型对物体轻微旋转不变性的识别能力，对于非水平或垂直的物体（如倾斜的瓶子、斜向的汽车）分割效果更好。

#### **二、 先进的模型训练与优化策略**

训练策略是决定模型最终性能上限的关键。我们对基准实验中的优化器和微调（Fine-Tuning）方法进行了显著升级。

*   **基准方法**：
    1.  **优化器**：采用带动量的随机梯度下降（SGD with Momentum）作为优化器。
    2.  **微调策略**：采用**单阶段微调**策略。即冻结骨干网络（Backbone）的全部参数，仅训练新添加的、随机初始化的分类头（Classifier Head）。

*   **我们的改进**：
    1.  **引入AdamW优化器**：我们采用了**AdamW**（Adam with Decoupled Weight Decay）优化算法。相比SGD，AdamW是一种**自适应学习率优化器**，它能为模型的每个参数计算独立的学习率，通常能带来更快的收敛速度。更重要的是，它修正了传统Adam中权重衰减（Weight Decay）的实现方式，使其在正则化方面更有效，有助于提升模型的泛化能力。

    2.  **实施两阶段微调 (Two-Stage Fine-Tuning)**：这是我们最核心的训练策略改进。
        *   **第一阶段：头部训练**。与基准方法相同，我们首先冻结强大的预训练骨干网络，仅训练分类头。**其目的是**让这个全新的、未经训练的头部在不干扰骨干网络优秀特征提取能力的前提下，快速学习PASCAL VOC数据集的类别特征。
        *   **第二阶段：整体微调**。在分类头经过几个周期的稳定训练后，我们**解冻整个骨干网络**，并使用一个**非常小**的学习率（通常是初始学习率的1/10或1/100）对整个模型进行训练。**其目的是**让骨干网络提取的通用特征（如边缘、纹理）能够根据PASCAL VOC这个特定数据集的特点进行微小的、精确的调整，从而实现模型性能的进一步压榨。

#### **三、 严谨的性能评估与模型选择机制**

如何科学地评估模型并选出最优版本，是衡量一个实验流程是否严谨的重要标准。我们在这方面引入了量化评估和自动化选择机制。

*   **基-准方法**：
    1.  **性能监控**：在训练过程中，仅监控**训练集损失（Training Loss）**。
    2.  **模型保存**：保存训练**最后一个周期（epoch）**的模型作为最终模型。

*   **我们的改进**：
    1.  **引入mIoU作为核心评估指标**：我们摒弃了仅使用损失函数作为评估标准的做法，引入了语义分割领域的**黄金标准——平均交并比（Mean Intersection over Union, mIoU）**。mIoU通过计算预测区域与真实区域的交集与并集之比，能够**直接、准确地衡量模型分割的精度**，远比间接的损失值更具说服力和可解释性。

    2.  **增加周期性验证循环 (Epoch-wise Validation)**：我们在每个训练周期结束后，都会在**独立的验证集**上运行一个完整的评估流程，计算当前模型的mIoU。**其目的**是实时监控模型在未见过数据上的泛化能力，从而能够及时发现**过拟合**等问题。

    3.  **基于验证性能的最佳模型保存 (Best Model Checkpointing)**：我们彻底改变了模型保存策略。不再盲目地保存最后一个周期的模型，而是在整个训练过程中，**只有当模型在验证集上的mIoU分数超过了历史最佳分数时，才将其权重保存下来**。这确保了我们最终得到的，是整个训练过程中泛化能力最强、表现最好的模型，极大地提升了实验结果的可靠性。

通过上述三个维度的系统性改进，我们的实验流程在专业性和严谨性上都得到了显著提升，最终训练出的模型在客观性能指标上也超越了基准模型。