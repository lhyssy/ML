
## 实验报告：创新与改进

本实验在物体识别的基础任务（CIFAR-10 分类）上，对实验手册中提供的基准流程（基于 MindSpore 框架的 LeNet-5 网络）进行了全面的、面向 SOTA（State-of-the-Art）技术的创新与改进。这些改进涵盖了深度学习框架、模型架构、数据处理以及训练策略等多个维度，旨在显著提升模型的特征提取能力和泛化性能。

### 一、核心模型架构的跨越式升级

[cite_start]原实验手册基于经典的 **LeNet-5 卷积神经网络（CNN）**架构 [cite: 427, 330][cite_start]，即使优化后的 LeNet5\_2 也仍属于浅层 CNN [cite: 344]。

本实验的核心创新是采用了先进的 **Swin Transformer** 模型架构：

| 改进点 | 实验手册（基准） | 本实验（创新） | 意义和优势 |
| :--- | :--- | :--- | :--- |
| **模型架构** | [cite_start]传统 CNN (LeNet-5/LeNet5\_2) [cite: 427, 344] | **Swin Transformer** (Vision Transformer) | 实现了从 CNN 到 Transformer 的跨越。Swin Transformer 基于**分层设计**和**局部窗口自注意力机制**，能够更有效地建模全局依赖关系，同时保持对图像尺度的可伸缩性，显著提升了特征提取能力。 |
| **框架** | [cite_start]MindSpore 1.5 [cite: 408] | PyTorch (基于前置代码环境推断) | 更换为更为主流的 PyTorch 深度学习框架，便于集成最新的 SOTA 模型（如 Swin Transformer）和复杂的训练技巧。 |

### 二、数据处理与增强策略的深度优化

[cite_start]原实验手册的数据预处理主要包括尺寸变更、归一化、随机裁剪和随机水平翻转 [cite: 323]。本实验在此基础上引入了多项 SOTA 级别的数据增强技术，以大幅提高模型的鲁棒性和泛化能力：

| 改进点 | 实验手册（基准） | 本实验（创新） | 意义和优势 |
| :--- | :--- | :--- | :--- |
| **高级增强** | [cite_start]仅随机裁剪和翻转 [cite: 323] | 1. **AutoAugment (CIFAR10 Policy)** | 自动学习最优的图像增强策略组合，超越人为设计的固定增强，进一步拓宽训练集分布。 |
| | | 2. **RandomErasing** (p=0.25) | 随机擦除图像中的一个矩形区域，模拟遮挡问题，迫使模型关注图像的非判别性部分，提高鲁棒性。 |
| **混合训练** | 未使用 | **MixUp/CutMix** (带概率混合) | 通过对图像及其标签进行线性/区域混合，平滑了标签，有效减少了模型在边界上的过拟合，是现代视觉任务的标配。 |

### 三、训练策略与优化器的全面升级

本实验采用了为训练高性能 Vision Transformer 模型设计的先进优化策略和超参数配置，以确保模型稳定收敛并达到最优性能：

| 改进点 | 实验手册（基准） | 本实验（创新） | 意义和优势 |
| :--- | :--- | :--- | :--- |
| **优化器** | [cite_start]Adam 或 Momentum [cite: 352] | **AdamW** (Weight Decay=0.05) | 采用 AdamW，它对 L2 正则化（即权重衰减）的处理更加合理，能有效防止大型模型过拟合，是 Transformer 模型的首选优化器。 |
| **学习率调度** | 未见详细 SOTA 策略 | **线性 Warmup + Cosine Annealing** | 采用 Warmup 策略克服训练初期梯度不稳定的问题；采用余弦退火策略使学习率平稳下降，避免卡在局部最优，提高模型最终精度。 |
| **损失函数** | [cite_start]交叉熵损失 (MindSpore: `SoftmaxCrossEntropyWithLogits`) [cite: 352] | **交叉熵损失 + 标签平滑 (Label Smoothing=0.1)** | 标签平滑减少了模型对硬标签的过度自信，提高了模型的泛化能力和鲁棒性。 |
| **稳定性** | 未见提及 | **梯度裁剪 (Gradient Clipping)** | 对梯度范数进行限制（max\_norm=5.0），防止梯度爆炸，这对训练复杂的 Vision Transformer 尤为重要。 |

通过上述从**模型架构**到**数据增强**再到**优化策略**的全流程创新，本实验将 CIFAR-10 任务从传统的 CNN 基准提升到了基于 Vision Transformer 的 SOTA 级别，显著提高了实验的学术深度和性能上限。