
## **实验报告：基于Attention U-Net及优化训练策略的医学图像分割**

**实验日期:** 2025年11月26日
**撰写人:** 李浩宇

### **摘要**

本实验在华为云《计算机视觉》实验手册提供的标准U-Net医学图像分割方案基础上，进行了一系列系统性的创新与改进。为解决标准U-Net在特征融合过程中的信息冗余问题，我们引入了**注意力机制（Attention Mechanism）**，构建了**Attention U-Net**模型，以增强模型对关键区域的特征表达能力。针对医学图像中普遍存在的类别不平衡问题，我们设计并采用了**交叉熵与Dice损失相结合的复合损失函数**。此外，我们实施了包括仿射变换和颜色抖动在内的**高级数据增强策略**，以提升模型的泛化能力。最后，我们集成了**学习率动态调度、早停（Early Stopping）和最优模型保存**等智能化训练策略，实现了训练过程的自动化与高效化。实验结果表明，经过改进的模型在分割精度和鲁棒性上均优于基线方案，验证了所提出改进策略的有效性。

---

### **1. 引言**

医学图像分割是计算机视觉在医疗领域中的一项核心任务，其目标是在医学影像（如CT、MRI、电子显微镜图像等）中精确地识别并勾勒出感兴趣的组织、器官或病灶的轮廓。精准的分割结果是后续进行临床诊断、疾病量化分析、手术规划及放射治疗等应用的关键前提。

本实验聚焦于ISBI（International Symposium on Biomedical Imaging）挑战赛中的电子显微镜神经元结构分割任务。实验手册提供了一个基于经典U-Net架构的基线实现方案，该方案为理解和应用深度学习于医学分割提供了坚实的基础。然而，为了追求更高的分割精度和更强的模型泛化能力，本报告旨在探索并实现一系列前沿的改进方法，以期超越基线模型的性能。

### **2. 基线方法回顾**

实验手册中的基线方法采用了经典的**U-Net**网络架构，其核心优势在于其对称的编码器-解码器结构和创新的“跳跃连接”（Skip Connections）。

*   **编码器（Encoder）**: 通过一系列卷积和池化层，逐步提取图像的深层语义特征，同时减小特征图的空间分辨率。
*   **解码器（Decoder）**: 通过上采样（如转置卷积）和卷积层，逐步恢复特征图的分辨率，并结合编码器对应层级的特征图进行特征融合，以生成精细的分割掩码。
*   **跳跃连接**: 将编码器路径中的浅层、高分辨率特征图直接传递并拼接（Concatenate）到解码器路径中，有效地结合了深层语义信息和浅层空间细节，极大地缓解了因网络深度增加导致的空间信息丢失问题。

**基线方法的局限性分析：**
尽管U-Net是一个强大且高效的架构，但其原始设计仍存在可优化的空间：
1.  **盲目特征融合**: 跳跃连接以一种“硬”拼接的方式融合特征，未区分特征的重要性，可能引入背景等无关区域的噪声，影响分割精度。
2.  **损失函数单一**: 仅使用交叉熵损失，在前景与背景像素数量严重不平衡的场景下，损失可能被数量占优的背景像素主导，导致模型对前景的分割能力不足。
3.  **训练策略静态**: 采用固定的学习率和训练周期，缺乏对训练动态的自适应调整，易陷入局部最优或发生过拟合。

### **3. 创新与方法改进**

为克服上述局限性，我们从模型架构、损失函数、数据处理和训练策略四个维度进行了系统性的创新与改进。

#### **3.1 模型架构升级：从U-Net到Attention U-Net**

**改进动机**: 标准U-Net的跳跃连接在融合深、浅层特征时，并未对特征进行筛选。我们希望模型能够自适应地“关注”与分割任务最相关的区域，同时抑制无关背景区域的干扰。

**实现方法**: 我们在U-Net的解码器部分，于特征拼接之前引入了**注意力门（Attention Gate, AG）**模块。
*   **工作原理**: 注意力门接收两个输入：一个来自解码器路径中较低层次、空间信息更粗糙的特征图 **(g)**；另一个来自编码器路径中对应层级、空间细节更丰富的特征图 **(x)**。
*   通过一系列线性变换和非线性激活（Sigmoid），注意力门会生成一个**注意力系数图 (α)**，其值域在之间。这个系数图与编码器特征图 **(x)** 进行逐元素相乘，得到加权后的特征图 **(x')**。
*   **效果**: 注意力系数图 **(α)** 中的高值区域对应模型认为重要的前景区域，低值区域则对应无关背景。通过这种方式，模型在特征融合前，便主动地增强了前景特征并抑制了背景特征，实现了更智能、更高效的特征融合。

#### **3.2 损失函数优化：复合损失函数（Combined Loss）**

**改进动机**: 医学图像分割任务普遍存在严重的类别不平衡问题。单独使用交叉熵（Cross-Entropy）损失函数，模型可能倾向于将所有像素预测为背景以获得较低的整体损失。

**实现方法**: 我们设计了一种结合**交叉熵损失**和**Dice损失**的复合损失函数。
*   **Dice损失**: 直接优化Dice相似系数（Dice Similarity Coefficient, DSC），这是一个衡量两个样本（预测掩码和真实掩码）重叠度的集合相似性度量。Dice损失对类别不平衡不敏感，能有效驱动模型学习前景区域的正确形状和大小。
*   **复合公式**:
    `L_total = w * L_CrossEntropy + (1 - w) * L_Dice`
    其中 `w` 是一个平衡权重。这种组合利用了交叉熵损失在像素级别提供平滑梯度和稳定训练的优势，同时借助Dice损失来应对类别不平衡，引导模型关注分割的整体空间一致性。

#### **3.3 数据处理增强：高级数据增强策略**

**改进动机**: 深度学习模型的性能高度依赖于数据量。在医学图像数据有限的情况下，必须通过数据增强来扩充数据集，以防止过拟合并提升模型的泛化能力。

**实现方法**: 在原有简单的旋转和翻转基础上，我们引入了更复杂且有效的数据增强技术：
1.  **仿射变换（Affine Transformations）**: 包括随机**缩放**和**错切（Shear）**，模拟了目标在成像过程中可能出现的形变。
2.  **颜色抖动（Color Jitter）**: 对图像的**亮度**和**对比度**进行随机调整，使模型对光照和成像条件的变化更具鲁棒性。

这些高级增强技术生成了更多样化的训练样本，迫使模型学习到更本质、更不变的特征。

#### **3.4 训练过程优化：智能化训练策略**

**改进动机**: 手动调整学习率和训练周期费时费力且效率低下。一个智能的训练框架应能自动适应模型的学习进程。

**实现方法**: 我们集成了一套现代化的训练监控与调整机制：
1.  **学习率调度器 (`ReduceLROnPlateau`)**: 该机制监控验证集上的关键性能指标（如Dice分数）。当指标在连续多个周期内不再提升时，它会自动降低学习率。这使得模型在训练初期能快速收敛，在后期能进行更精细的权重调整，有助于跳出局部最优。
2.  **早停机制（Early Stopping）**: 同样监控验证集性能。如果性能在设定的“耐心周期”（Patience Epochs）内持续没有改善，训练将自动终止。这不仅节约了大量的计算资源，更是防止模型过拟合的有效手段。
3.  **最优模型保存（Best Model Checkpointing）**: 在整个训练过程中，只有当验证集性能创下新高时，当前的模型权重才会被保存。这确保了我们最终用于评估和部署的是整个训练过程中表现最佳的模型，而非最后一次迭代的模型。

### **4. 实验设置**

*   **数据集**: ISBI 2012 电子显微镜（EM）分割数据集。
*   **数据划分**: 80% 的数据用于训练，20% 用于验证。
*   **硬件环境**: NVIDIA RTX 3090 (CUDA)。
*   **软件框架**: PyTorch 1.12+，NumPy，OpenCV，Matplotlib。
*   **核心超参数**:
    *   **优化器**: AdamW
    *   **初始学习率**: 1e-4
    *   **批量大小 (Batch Size)**: 4
    *   **最大训练周期 (Max Epochs)**: 100
    *   **早停耐心周期 (Patience)**: 10

### **5. 结果与分析**

*   **定量分析**: 相比于基线U-Net模型，我们改进的Attention U-Net在验证集上取得了显著更高的**Dice分数**。这证明了注意力机制和复合损失函数在提升分割精度上的有效性。同时，得益于早停机制，模型通常在达到最佳性能后很快停止训练，避免了不必要的计算开销。
*   **定性分析**: 通过可视化预测结果可以观察到，Attention U-Net生成的分割掩码**边界更清晰、更贴合真实轮廓**。对于一些模糊或粘连的细胞边界，改进后的模型表现出更强的分辨能力，**假阳性（将背景误判为前景）和假阴性（将前景漏掉）的情况均有明显减少**。这直观地展示了模型性能的提升。

### **6. 结论与展望**

本实验成功地在基线U-Net方案的基础上，通过引入**Attention U-Net架构、复合损失函数、高级数据增强及智能化训练策略**，显著提升了医学图像分割的性能。这些改进不仅提高了模型的分割精度，也增强了其鲁棒性和训练效率，展示了将前沿深度学习技术应用于解决实际问题的巨大潜力。

未来的工作可以从以下几个方向展开：
1.  **探索更先进的架构**: 如U-Net++、TransUNet等结合了Transformer的模型。
2.  **后处理技术**: 引入条件随机场（CRF）等方法对分割结果进行后处理，以进一步平滑边界。
3.  **模型泛化性测试**: 将训练好的模型在其他不同模态的医学图像数据集上进行测试，评估其跨领域泛化能力。